#+title: A Review of audio declipping through a sparse prior
#+author: Pierre-Antoine Comby
#+date:  2020-12-07
#+property: header-args:python :tangle python/audioDeclipping.py :exports none :session ses1
#+options: toc:nil
#+language: en
#+latex_class_options: [twocolumn]
#+latex_header: \usepackage{bm}
#+latex_header: \usepackage{bbold}
#+latex_header: \usepackage[top=2cm,bottom=2cm,left=1cm,right=1cm]{geometry}
#+latex_header: \renewcommand{\vec}{\bm}
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport


#+begin_abstract
The inverse problem of audio declipping is ill posed and a regularization prior is thus needed, in particular a sparse synthesis (or in dual space a analysis) are presented and tested. In the following, we implement and extends the methods presented in XX
#+end_abstract


* The problem

The saturation of an audio signal occurs often in signal processing and communication, when the original or signal are not available, one requires to reconstruct the parts of the signal which have been lost.
We  consider an original signal \(\vec{x} \in \mathbb{R}^{N}\) which have been clipped to produced \(\vec{y}\).

\[y =
\begin{cases}
x_{i} & \text{ if }  \tau^{-} \le x_{i} \le \tau^{+} \\
\tau^{+} & \text{ if }  \tau^{+} \le x_{i} \\
\tau^{+} & \text{ if }  x_{i} \le \tau^{-}
\end{cases}\]

Our goal is to retrieve \(\hat{\vec{x}}\), which is as close as possible from the original signal  \(\vec{x}\)

** Constrained Optimisation
The indexes of \(\vec{y}\) can be separated into three sets:
- \( \Omega_r = \{i \in 1,...,N | y_i = x_i \} \)
- \( \Omega_c^+ = \{i \in  1,...,N | y_i =  \tau \} \)
- \( \Omega_c^- = \{i \in 1, ..., N| y_i = -\tau \} \)

A correct estimation of \(\vec{x}\)  should thus verify:

- \(\hat{\vec{x}}(\Omega_r) = \vec{y}(\Omega_r) \)
- \(\hat{\vec{x}}(\Omega_c^+) \ge \tau \)
- \(\hat{\vec{x}}(\Omega_c^-) \le -\tau\)
These constraints are denoted as \(\hat{\vec{x}} \in \Gamma(y)\). \(\Gamma(\vec{y})\) is a convex set, and enforcing the previous constraint will be assured by projecting the candidates estimation on \(\Gamma\). Such projection can be implemented as follows:
\[ P_{\Gamma(\vec{y})}(\vec{x}) = \max(\min(\vec{x},\vec{\gamma}_{-}),\vec{\gamma}_{+})\]

With:
\[\begin{cases}
\vec{\gamma}_{-}(\Omega_{r}) &= y(\Omega_{r}) \\
\vec{\gamma}_{-}(\Omega_{c}^{-}) &= \tau^{-} \\
\vec{\gamma}_{-}(\Omega_{r}^{+}) &= +\infty \\
\end{cases} \qquad
\begin{cases}
\vec{\gamma}_{+}(\Omega_{r}) &= y(\Omega_{r}) \\
\vec{\gamma}_{+}(\Omega_{c}^{-}) &= -\infty \\
\vec{\gamma}_{+}(\Omega_{r}^{+}) &= \tau^{+} \\
\end{cases}\]

** Regularization trough Sparsity

The state of the art for the regularization is to use a sparsity (or in dual space, co-sparsity) prior to solve the inverse problem of declipping. Other approach that are also worth mentioning are: linear prediction, minimization of th energy of high order derivative and psycoacoustic.

The sparsity prior rely on a time-frequency analysis, (or synthesis in a dual framework). We consider the Analysis operator \(\vec{A}\), such that \(\vec{z} =\vec{Ax}\), with \(\vec{z}\) the sparse representation of $x$ in a dictionnary space (e.g. a Gabor frame).
The /Analysis Sparse Audio Declipper/ (A-SPADE) Problem is  therefore:

\begin{equation}
\label{eq:ASPADE}
\arg\min_{x\in \mathbb{R}^{N}} \|z\|_{0} \text{ s.t. } \|\vec{Ax-z}\|_{2} \le \epsilon \text{ and } x\in \Gamma(\vec{y})
\end{equation}
Or on  the dual side, the Synthesis Sparse Audio Declipper (S-SPADE):
\begin{equation}
\label{eq:SSPADE}
\arg\min_{x\in \mathbb{R}^{N}} \|z\|_{0} \text{ s.t. } \|\vec{x-Dz}\|_{2} \le \epsilon \text{ and } x\in \Gamma(\vec{y})
\end{equation}

* Algorithms
** ADMM
Both  \eqref{eq:ASPADE} and  \eqref{eq:SSPADE} are solvable via the Alternating Direction Method of Multipliers (ADMM). ADMM can solve problem of the form
\begin{equation}
\label{eq:ADMM}
\min_{\vec{x}} f(\vec{x}) + g(\vec{Ax}) \\ \iff \min_{\vec{x,z}} f(\vec{x})+g(\vec{z}) \text{ s.t } \vec{Ax}-z = 0
\end{equation}
With \(f,g\)  two convex function and \(\vec{A}\) A linear operator. In our case we can write the A-SPADE and S-SPADE problem as:
\begin{equation}
\label{eq:2}
\arg\min_{x,z,k} \underbrace{\mathbb{1}_{l_{0}\le k}(z)}_{g(\vec{z})} + \underbrace{\mathbb{1}_{\Gamma(y)}(\vec{x})}_{f(\vec{x})}  \text{ s.t. } \vec{Ax}=\vec{z}
\end{equation}
With a fixed \(k\)  we identify an ADMM solvable problem, (but only locally, as the \(l_{0}\) norm is not a smooth convex function).
Consequently, we have the following iterative scheme for A-SPADE:
\begin{subequations}
\label{eq:ASPADE-step}
\begin{align}
\vec{x}^{(i+1)}&=\underset{\vec{x}\in \Gamma(\vec{y})}{\operatorname{argmin}}\left\|A \vec{x}-\vec{z}^{(i)}+\vec{u}^{(i)}\right\|_{2}^{2} \\
\vec{z}^{(i+1)}&=\underset{\vec{z}\in l_{0}\le k}{\operatorname{argmin}}\left\|A \vec{x}^{(i+1)}-\vec{z}+\vec{u}^{(i)}\right\|_{2}^{2}\\
\vec{u}^{(i+1)}&=\vec{u}^{(i)}+A \vec{x}^{(i+1)}-\vec{z}^{(i+1)}
\end{align}
\end{subequations}
and an analoguous one for S-SPADE *cite*:
\begin{subequations}
\label{eq:SSPADE-step}
\begin{align}
\vec{z}^{(i+1)}&=\underset{\vec{z}\in l_{0}\le k}{\operatorname{argmin}}\left\|D \vec{z}-\vec{x}^{(i)}+\vec{u}^{(i)}\right\|_{2}^{2}\\
\vec{x}^{(i+1)}&=\underset{\vec{x}\in \Gamma(\vec{y})}{\operatorname{argmin}}\left\|D \vec{z}^{(i+1)}-\vec{x}+\vec{u}^{(i)}\right\|_{2}^{2}\\
\vec{u}^{(i+1)}&=\vec{u}^{(i)}+D \vec{z}^{(i+1)}-\vec{x}^{(i+1)}
\end{align}
\end{subequations}
The hypothesis of a \(k\)-sparse vector will  be incrementaly relaxed in the final algorithm presented later. In the case \(\vec{D}^{\star} = \vec{A}\)  the two algorithm are completely equivalent, and S-SPADE is entirely the dual representation of A-SPADE: \(\vec{z}\) become the primal variable, and \(\vec{x}\) the dual one.


** Implementation

Both minimization steps provide projection on a convex set. With the hypothesis of  a Parseveal frame  (\(\vec{A^{*}A}= \vec{I}\) or \(\vec{D^{*}D} = \vec{I}\)) we have
\begin{subequations}
\label{eq:ASPADE-step2}
\begin{align}
\vec{x}^{(i+1)}&= P_{\Gamma(\vec{y})}(\vec{A}^{*}(z^{(i)}-u^{(i)}))\\
\vec{z}^{(i+1)}&=\mathcal{H}_{k}(\vec{A}\vec{x}^{(i+1)}+\vec{u}^{(i)})\\
\vec{u}^{(i+1)}&=\vec{u}^{(i)}+A \vec{x}^{(i+1)}-\vec{z}^{(i+1)}
\end{align}
\end{subequations}
and S-SPADE:
\begin{subequations}
\label{eq:SSPADE-step2}
\begin{align}
\vec{z}^{(i+1)}&=\mathcal{H}_{k}(\vec{D}^{*}(\vec{x}^{(i)}-\vec{u}^{(i)}))\\
\vec{x}^{(i+1)}&=P_{\Gamma(\vec{y})}(\vec{D}^{*}(\vec{x}-\vec{u}^{(i)}))\\
\vec{u}^{(i+1)}&=\vec{u}^{(i)}+D \vec{z}^{(i+1)}-\vec{x}^{(i+1)}
\end{align}
\end{subequations}


* Results
The presented algorithm have been implemented using Python, and its modules Numpy and Scipy.
All the sources of this project are available at [[https://gitlab.crans.org/comby/audioDeclipping]]


* Conclusion
** Possibilities of enhancement

 - Use a double frame operator STFT trnsform with a transient and tonal decomposition
 - Test with Wavelet transform
 - In a more general way, a smarter sampling of the time frequency grid.
 - Combine sparsity priori with other prior of the literature


